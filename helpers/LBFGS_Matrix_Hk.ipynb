{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use(\"MACOSX\")\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as optimize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fun(x):\n",
    "    x.shape=(-1, 1)\n",
    "    return .5*x[0, 0]**2 + x[0, 0]* np.cos(x[1, 0])\n",
    "\n",
    "def test_jac(x):\n",
    "    x.shape=(-1, 1)\n",
    "    return np.array([[x[0, 0] + np.cos(x[1, 0])],\n",
    "                      [-x[0, 0] * np.sin(x[1, 0])]])\n",
    "\n",
    "def test_hess(x):\n",
    "    x.shape=(-1, 1)\n",
    "    return np.array([[           1.,        -np.sin(x[1, 0])],\n",
    "                     [-np.sin(x[1, 0]), -x[0, 0] * np.cos(x[1, 0])]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "\n",
    "xg, yg = np.linspace(-2, 2, 51), np.linspace(-6, 6, 51)\n",
    "def mat_fun(x_g, x_):\n",
    "    Z = np.zeros((xg.size, yg.size))\n",
    "\n",
    "    for i in range(Z.shape[0]):\n",
    "        for j in range(Z.shape[1]):\n",
    "            Z[j, i] = test_fun(np.array([xg[i], yg[j]]))\n",
    "    return Z\n",
    "X, Y = np.meshgrid(xg,yg)\n",
    "ax.contour(X, Y, mat_fun(xg, yg))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2 # Dimension of x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gamma = 1\n",
    "m = 3\n",
    "S = np.zeros((n,0))\n",
    "Y = np.zeros((n,0))\n",
    "R = np.zeros((0,0))\n",
    "STgrad=np.array((0,m))\n",
    "YTgrad=np.array((0,m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial history:\n",
    "x_old = np.array([[0],[1]])\n",
    "grad_old = test_jac(x_old)\n",
    "\n",
    "# line search\n",
    "step =optimize.minimize_scalar(fun = lambda alpha : test_fun(x_old  - grad_old * alpha) ,bounds=(0,2),method=\"bounded\" ).x\n",
    "x     = x_old - grad_old * step\n",
    "assert test_fun(x) < test_fun(x_old)\n",
    "grad = test_jac(x)\n",
    "\n",
    "k=1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "alpha = np.linspace(0,2)\n",
    "plt.plot(alpha,[test_fun(x_old  - grad_old * a) for a in alpha])\n",
    "plt.axvline(step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S: [[ 0.         -0.8279051   0.03863815]\n",
      " [-0.54030231 -0.69665812  0.03331417]]\n",
      "Y: [[-0.25173224  0.21401065  0.03925223]\n",
      " [-0.24282335 -0.24821198  0.03461154]]\n"
     ]
    }
   ],
   "source": [
    "# Update Sk,Yk\n",
    "\n",
    "if k > m:\n",
    "    S=np.roll(S,-1)\n",
    "    S[:,-1] = (x - x_old).flat\n",
    "    Y=np.roll(Y,-1)\n",
    "    Y[:,-1]  = (grad - grad_old).flat\n",
    "    \n",
    "else :\n",
    "    S = np.hstack([S,x - x_old])\n",
    "    Y = np.hstack([Y,grad - grad_old])\n",
    "print(\"S: {}\".format(S))\n",
    "print(\"Y: {}\".format(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<numpy.flatiter at 0x7f96b417d800>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x - x_old).flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.\n",
    "grad2 = np.sum(np.asarray(grad)**2) #ok\n",
    "YTgrad_prev = STgrad.copy() # scalar\n",
    "YTgrad_prev = YTgrad.copy()\n",
    "STgrad = np.dot(S.T,grad)\n",
    "YTgrad = np.dot(Y.T,grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. # TOOPTIMIZE\n",
    "sprevTgradprev =  np.dot(S[:,-1].T,grad_old) # sk-1T gk-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before\n",
      "R: [[ 0.29192658  0.13601151 -0.11563045]\n",
      " [ 0.          0.37640599  0.05640371]\n",
      " [ 0.          0.          0.09419725]]\n",
      "after\n",
      "R: [[ 0.37640599  0.05640371 -0.0187007 ]\n",
      " [ 0.          0.09419725 -0.05660953]\n",
      " [ 0.          0.          0.00266969]]\n",
      "YTY: [[ 0.1223323   0.00639828 -0.01828554]\n",
      " [ 0.00639828  0.10740975 -0.0001906 ]\n",
      " [-0.01828554 -0.0001906   0.0027387 ]]\n",
      "D: [[ 0.13119801  0.          0.        ]\n",
      " [ 0.         -0.00426162  0.        ]\n",
      " [ 0.          0.          0.00266969]]\n"
     ]
    }
   ],
   "source": [
    "#4. \n",
    "\n",
    "ykm12 = np.dot(Y[:,-1].T,Y[:,-1])\n",
    "\n",
    "print(\"before\")\n",
    "print(\"R: {}\".format(R))\n",
    "if k > m:\n",
    "    R = np.roll(R,(-1,-1),axis=(0,1))# mxm Matrix hold by all Processors \n",
    "    R[-1,:] = 0\n",
    "    R[:,-1] = np.dot(S.T, Y[:,-1])# TOOPTIMIZE\n",
    "elif k ==1:\n",
    "    R= np.array(np.dot(S.T,Y))\n",
    "else :\n",
    "    R = np.vstack([R, np.zeros(k-1)])\n",
    "    R = np.hstack([R,np.dot(S.T, Y[:,-1]).reshape(k,1)])\n",
    "    \n",
    "YTY = np.dot(Y.T,Y) #TOOPTIMIZE\n",
    "\n",
    "D = np.diag(np.einsum(\"ik,ik -> k\",S,Y))\n",
    "\n",
    "print(\"after\")\n",
    "print(\"R: {}\".format(R))\n",
    "print(\"YTY: {}\".format(YTY))\n",
    "print(\"D: {}\".format(D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.\n",
    "gamma = D[-1,-1] / ykm12# n.b. D[-1,-1] = sk-1T yk-1 = yk-1T sk-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. \n",
    "Rinv = np.linalg.inv(R) # TODO: profitiert das davon dass R eine Dreiecksmatrix ist ?\n",
    "\n",
    "RiSg = Rinv.dot(STgrad)\n",
    "\n",
    "p = np.vstack([Rinv.T.dot(D+gamma*YTY).dot(RiSg) - gamma * Rinv.T.dot(YTgrad)\n",
    "               ,- RiSg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7.\n",
    "Hgrad = gamma*grad + np.hstack([S,gamma*Y]).dot(p) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linesearch\n",
    "\n",
    "alpha =optimize.minimize_scalar(fun = lambda alpha : test_fun(x  - Hgrad * alpha) ,bounds=(0,10),method=\"bounded\" ).x\n",
    "x_old= x \n",
    "x     = x  - Hgrad * alpha\n",
    "assert test_fun(x) < test_fun(x_old)\n",
    "grad_old=grad\n",
    "grad = test_jac(x)\n",
    "\n",
    "ax.plot(x[0],x[1],\"+k\")\n",
    "ax.annotate(k,x)\n",
    "k = k+1\n",
    "fig.canvas.draw()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
